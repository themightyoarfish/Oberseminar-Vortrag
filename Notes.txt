VERSATZSCHÄTZUNG

* wie bekommt man aus einer Stereoaufnahme (Referenzbild + aktuelles Bild) die
  Posedifferenz?
* [Erläuterung der Grafik]
* Es gibt eine Bezihung zwischen Bildkoordinaten in Frame 1 und Frame 2:
   + Kameraframes sind durch (R,T) gegeneinander transformiert
   + Bilder der Bildpunkte sind Strahlen, ergo nur bis auf Skalierung bestimmt
   + T-dach ist Matrixschreibweise für das Kreuzprodukt mit T
   + So gelangt man zur Essentiellen Matrix, die einen Punkt auf seine
   Epipolarlinie im anderen Frame abbildet
* Mit Hilfe der Epipolargleichung kann man nun mit Punktkorrespondenzen
  Gleichungen aufstellen, und das resultierenden LGS lösen/optimieren
  + 8-Punkt-Algorithmus: E hat max. 8 DOF wegen Skalierung, also braucht man
  maximal 8 Korrespondenzen
  + in der Realität verrauscht, also braucht man mehr
  + Überbestimmung führt zu einer Lösung mit kleinstem Fehlerquadrat
  + Zudem ist die Lösung nicht unbedingt Essentiell (2 gleiche Singulärwerte) ->
  Projektion auf Raum aller Essentiellen Matrizen
  + Es geht auch mit 5 Punkten, da E eigentlich nur 5 DOF (3 für R, 3 für T, -1
  für Skalierung)
  + Es gibt 4 Lösungen für (R,T), jedoch macht nur eine Sinn, welche die Punkte
  vor beiden Kameras platziert, wenn man ihre 3D-Triangulation berechnet.

KORRESPONDENZFINDUNG

* Die Leute vom MIT lassen den User manuell labeln (möglicherweise unersetzlich
  bei historischen, sehr alten Aufnahmen, die nicht viel mit der Realität gemein
  haben)
* In unserem Ansatz versuchen wir es mit automatischer Feature-Erkennung, was
  weniger drastische Veränderungen vorraussetzt und die Anwendbarkeit
  einschränkt. Idealerweise wird die Korrespondenzfindung später so erweitert,
  dass die App mit historischen Bildern klarkommt. (Darüber darf Ann-Katrin sich
  dann den Kopf zerbrechen)
* Detektoren gibt es viele, z.B. SURF oder SIFT, die viele Invarianzen haben und
  als verlässlich gelten. Vor allem SIFT ist relativ langsam, SURF ist deutlich
  schneller. Beide benutzen reellwertige Deskriptoren, was beim Matching zu einem
  relativ aufwendigen L2-Norm-Vergleich führt.
* Es wurden daher einige Deskriptoren entwickelt, die Binärstrings sind (BRIEF,
  ORB, KAZE-Deskriptor), die man schneller vergleichen kann, was auf schwächerer
  Hardware von Vorteil ist
* AKAZE ist ein Detektor, der binäre Deskriptoren berechnet, und schneller als
  SURF sein soll bei mindestens so guter Genauigkeit
* Hier muss man auch etwas herumspielen, bis man die richtigen Parameter
  gefunden hat und dabei Performanz gegen Featurezahl und -salienz abwägen
* Es ist aufgrund sehr unterschiedlicher Parametertypen schwer, die Detektoren
  zu verlgeichen, AKAZE scheint zumindest etwas schneller zu sein
* Bisher hängen die Ergebnisse noch stark von der Art des Detektors und den
  Parametern ab

Nun haben wir eigentlich alles: Korrespondenzen und Methode zur
Versatzberechnung
